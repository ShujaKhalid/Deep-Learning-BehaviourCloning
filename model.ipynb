{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pull the acquired data from the csv file\n",
    "import csv\n",
    "import pandas\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import sklearn\n",
    "from random import shuffle\n",
    "import os\n",
    "import csv\n",
    "\n",
    "samples = []\n",
    "with open('./driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the generator and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = './IMG/'+batch_sample[0].split('\\\\')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extract the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only the center camera images as training data to the model\n",
    "with open('./driving_log.csv') as csvfile:\n",
    "    data = pandas.read_csv(csvfile, header=None)\n",
    "\n",
    "data_array = np.array(data) # convert to numpy array\n",
    "center_view = list()\n",
    "right_view = list()\n",
    "left_view = list()\n",
    "\n",
    "#cen_images = data_array[:,0]\n",
    "cen_images = glob.glob('./IMG/center*.jpg')\n",
    "rig_images = glob.glob('./IMG/right*.jpg')\n",
    "lef_images = glob.glob('./IMG/left*.jpg')\n",
    "\n",
    "for i in cen_images:\n",
    "    center_view.append(cv2.imread(i))\n",
    "for i in rig_images:\n",
    "    right_view.append(cv2.imread(i))\n",
    "for i in lef_images:\n",
    "    left_view.append(cv2.imread(i))\n",
    "\n",
    "center_view = np.array(center_view) # image array ready!\n",
    "right_view = np.array(right_view) # image array ready!\n",
    "left_view = np.array(left_view) # image array ready!\n",
    "#print(center_view.shape) \n",
    "\n",
    "steer_angle = data_array[:,3] # steer-angle array ready!\n",
    "steer_angle_left = data_array[:,3]+0.2 # steer-angle array ready!\n",
    "steer_angle_right = data_array[:,3]-0.2 # steer-angle array ready!\n",
    "#print(steer_angle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Augment the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a more generalized model, more training data can be created be flipping the images along the vertical axis\n",
    "center_view_flip = np.flip(center_view, axis=2)\n",
    "print(('Shape of center_view_flip:{}').format(center_view_flip.shape))\n",
    "print(('Shape of center_view:{}').format(center_view.shape))\n",
    "\n",
    "index=1000\n",
    "# Full frame\n",
    "plt.figure()\n",
    "plt.imshow(np.squeeze(center_view[index]))\n",
    "#print(('Steering angle:{}').format(steer_angle[index]))\n",
    "plt.title('160x320 frame - steer_angle: ' + str(steer_angle[index]))\n",
    "plt.figure()\n",
    "plt.imshow(np.squeeze(center_view_flip[index]))\n",
    "#print(('Steering angle:{}').format(-steer_angle[index]))\n",
    "plt.title('160x320 frame - steer_angle: ' + str(-steer_angle[index]))\n",
    "\n",
    "# Cropped frame\n",
    "crop_y_top = 70 # Suggested value was 50\n",
    "crop_y_bot = 20\n",
    "\n",
    "def crop_array(crop_y_top, crop_y_bot, arr):\n",
    "    arr_crop = arr[:, crop_y_top:arr.shape[1]-crop_y_bot, :]\n",
    "    return arr_crop\n",
    "\n",
    "center_view_crop = crop_array(crop_y_top, crop_y_bot, center_view)\n",
    "center_view_flip_crop = crop_array(crop_y_top, crop_y_bot, center_view_flip)\n",
    "right_view_crop = crop_array(crop_y_top, crop_y_bot, right_view)\n",
    "left_view_crop = crop_array(crop_y_top, crop_y_bot, left_view)\n",
    "\n",
    "# Display the images\n",
    "plt.figure()\n",
    "plt.imshow(np.squeeze(center_view_crop[index]))\n",
    "plt.title('Cropped ' + str(center_view.shape[1]-crop_y_bot-crop_y_top) + 'x' + str(320) + ' frame - steer_angle: ' + str(steer_angle[index]))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.squeeze(center_view_flip_crop[index]))\n",
    "plt.title('Cropped ' + str(center_view_flip_crop.shape[1]-crop_y_bot-crop_y_top) + 'x' + str(320) + ' frame - steer_angle: ' + str(-steer_angle[index]))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.squeeze(right_view_crop[index]))\n",
    "plt.title('Cropped ' + str(right_view_crop.shape[1]-crop_y_bot-crop_y_top) + 'x' + str(320) + ' frame - steer_angle: ' + str(steer_angle_right[index]))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.squeeze(left_view_crop[index]))\n",
    "plt.title('Cropped ' + str(left_view_crop.shape[1]-crop_y_bot-crop_y_top) + 'x' + str(320) + ' frame - steer_angle: ' + str(steer_angle_left[index]))\n",
    "\n",
    "\n",
    "# Dimensions after cropping\n",
    "print(('Shape of center_view_flip_crop:{}').format(center_view_flip_crop.shape))\n",
    "print(('Shape of center_view_crop:{}').format(center_view_crop.shape))\n",
    "print(('Shape of center_view:{}').format(center_view.shape))\n",
    "print(('Shape of right_view:{}').format(right_view.shape))\n",
    "print(('Shape of left_view:{}').format(left_view.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign training data\n",
    "X_train = np.concatenate((center_view, center_view_flip, left_view, right_view))\n",
    "y_train = np.concatenate((steer_angle, -steer_angle, steer_angle_left, steer_angle_right))\n",
    "print(('Shape of X_train:{}').format(X_train.shape))\n",
    "print(('Shape of y_train:{}').format(y_train.shape))\n",
    "X_train, y_train = sklearn.utils.shuffle(X_train, y_train)\n",
    "print(('Shape of X_train:{}').format(X_train.shape))\n",
    "print(('Shape of y_train:{}').format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Flatten, Convolution2D, Dense, Activation, Dropout, Lambda, Cropping2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Modified NVIDIA model\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]))) # Normalize and mean center the data\n",
    "model.add(Cropping2D(cropping=((crop_y_top,crop_y_bot), (0,0))))\n",
    "model.add(Convolution2D(24,5,5, subsample=(2,2), activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Convolution2D(36,5,5, subsample=(2,2), activation='relu'))\n",
    "model.add(Convolution2D(48,3,3, subsample=(2,2), activation='relu'))\n",
    "model.add(Convolution2D(64,3,3, subsample=(2,2), activation='relu'))\n",
    "model.add(Convolution2D(72,3,3, subsample=(2,2), activation='relu'))\n",
    "#model.add(Convolution2D(84,3,3, subsample=(2,2), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.3, shuffle=True, nb_epoch=5, verbose=1)\n",
    "#Generator not used because sufficient memory already available\n",
    "#model.fit_generator(train_generator, samples_per_epoch=len(train_samples), validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=7, verbose=1)\n",
    "model.save('model.h5')\n",
    "print()\n",
    "print('--- Model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
